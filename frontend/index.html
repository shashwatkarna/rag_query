<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Zero-Latency Voice Agent</title>
    <style>
        body {
            font-family: 'Inter', sans-serif;
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
            height: 100vh;
            background: #111;
            color: white;
            margin: 0;
        }

        .container {
            text-align: center;
        }

        #status {
            margin-bottom: 20px;
            color: #888;
            font-size: 0.9em;
        }

        #mic-btn {
            width: 80px;
            height: 80px;
            border-radius: 50%;
            border: none;
            font-size: 32px;
            background: #FF4F4F;
            color: white;
            cursor: pointer;
            transition: 0.2s;
            box-shadow: 0 0 20px rgba(255, 79, 79, 0.4);
        }

        #mic-btn.listening {
            background: white;
            color: #FF4F4F;
            animation: pulse 1.5s infinite;
        }

        @keyframes pulse {
            0% {
                box-shadow: 0 0 0 0 rgba(255, 255, 255, 0.4);
            }

            70% {
                box-shadow: 0 0 0 20px rgba(255, 255, 255, 0);
            }

            100% {
                box-shadow: 0 0 0 0 rgba(255, 255, 255, 0);
            }
        }

        #transcript {
            margin-top: 30px;
            font-size: 1.2em;
            max-width: 600px;
            line-height: 1.5;
            color: #eee;
            min-height: 50px;
        }

        #logs {
            margin-top: 20px;
            font-family: monospace;
            font-size: 0.8em;
            color: #444;
            text-align: left;
            max-width: 600px;
            width: 100%;
            height: 150px;
            overflow-y: auto;
            background: #222;
            padding: 10px;
            border-radius: 8px;
        }
    </style>
</head>

<body>
    <div class="container">
        <h1>üéôÔ∏è Voice Agent</h1>
        <div id="status">Ready to connect...</div>
        <button id="mic-btn">üé§</button>
        <div id="transcript">...</div>
        <div id="logs"></div>
    </div>

    <script>
        const micBtn = document.getElementById('mic-btn');
        const statusEl = document.getElementById('status');
        const transEl = document.getElementById('transcript');
        const logsEl = document.getElementById('logs');

        let ws;
        let mediaRecorder;
        let isRecording = false;

        function log(msg) {
            logsEl.innerHTML += `<div>> ${msg}</div>`;
            logsEl.scrollTop = logsEl.scrollHeight;
        }

        // Initialize Audio Context for playback
        const audioCtx = new (window.AudioContext || window.webkitAudioContext)();
        let audioQueue = [];
        let isPlaying = false;

        async function playAudioChunk(arrayBuffer) {
            // Decode and play generic audio chunk
            const audioBuffer = await audioCtx.decodeAudioData(arrayBuffer);
            const source = audioCtx.createBufferSource();
            source.buffer = audioBuffer;
            source.connect(audioCtx.destination);
            source.start(0);
        }

        function connect() {
            ws = new WebSocket("ws://localhost:8001/ws");

            ws.onopen = () => {
                statusEl.innerText = "Connected";
                log("WebSocket Connected");
            };

            ws.onmessage = async (event) => {
                // If it's a blob/binary, it's audio
                if (event.data instanceof Blob) {
                    log("Received Audio Chunk");
                    const arrayBuffer = await event.data.arrayBuffer();
                    playAudioChunk(arrayBuffer);
                    return;
                }

                // If text
                const data = JSON.parse(event.data);

                if (data.type === "filler") {
                    log("ü§ñ Filler: " + data.text);
                    statusEl.innerText = data.text;
                }

                if (data.type === "final_result") {
                    transEl.innerText = data.text;
                    log("‚úÖ Answer: " + (data.spoken_text || "Found result"));
                }
            };

            ws.onclose = () => { statusEl.innerText = "Disconnected"; };
        }

        async function startRecording() {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                mediaRecorder = new MediaRecorder(stream, { mimeType: 'audio/webm' }); // Browsers often default to webm

                // Deepgram expects raw or wrapped audio. 
                // For simplicity in this demo, sending the mime-type header first might be needed in a rigorous app,
                // but raw streaming often works if format is standard.
                // IMPORTANT: Deepgram via Websocket often needs RAW wav/pcm.
                // Browsers don't easily stream raw PCM via MediaRecorder.
                // WE WILL USE A Simple Hack: Send the WebM blobs. Deepgram is smart enough to handle WebM/Opus usually.

                mediaRecorder.ondataavailable = (event) => {
                    if (event.data.size > 0 && ws.readyState === WebSocket.OPEN) {
                        ws.send(event.data);
                    }
                };

                mediaRecorder.start(100); // 100ms chunks
                isRecording = true;
                micBtn.classList.add('listening');
                statusEl.innerText = "Listening...";

            } catch (err) {
                console.error(err);
                alert("Microphone access denied");
            }
        }

        function stopRecording() {
            if (mediaRecorder) {
                mediaRecorder.stop();
                isRecording = false;
                micBtn.classList.remove('listening');
                statusEl.innerText = "Processing...";
                // Send 'stop' message? Deepgram listens continuously usually.
            }
        }

        micBtn.onclick = () => {
            if (!isRecording) startRecording();
            else stopRecording();
        };

        connect();
    </script>
</body>

</html>